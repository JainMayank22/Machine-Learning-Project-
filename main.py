# -*- coding: utf-8 -*-
"""FinalSubmission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10S2qiBkqe8pUhw-9c7lsFT0pbuHu5Ck2
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import tensorflow as tf

# pip install tensornets

import tensornets as nets
import cv2 
import numpy as np
import time

inp = tf.placeholder(tf.float32, [None, 416, 416, 3])
model = nets.YOLOv3COCO(inp, nets.Darknet19)

from google.colab.patches import cv2_imshow

import random

np.random.seed()
classes_list=[1,2,3,5,7]
COLORS = np.random.randint(0, 255, size=(80, 3), dtype = "uint8")

classes_list=[1,2,3,5,7]
classes={'1':'bicycle','2':'car','3':'bike','5':'bus','7':'truck'}
with tf.Session() as ses:
    ses.run(model.pretrained())   
    
    
    img1 = cv2.imread("b.jpg")
    
    img=cv2.resize(img1,(416,416))
    imge=np.array(img).reshape(-1,416,416,3)
    start=time.time()
    preds = ses.run(model.preds, {inp: model.preprocess(imge)})
    

    print(" %s time in seconds" % (time.time() - start)) 
    boxes = model.get_boxes(preds, imge.shape[1:3])
    
    boxes1=np.array(boxes)
    (H, W) = imge.shape[0:2]
    
    confidence = []
    bxs = []
    cids = []
    cnt = []
    for j in classes_list:
        c =0
        if str(j) in classes:
          
          if len(boxes1) !=0:
            
            
            for k in range(len(boxes1[j])):
                box=boxes1[j][k]
                if boxes1[j][k][4]>=.50:
                    
                    confidence.append(float(boxes1[j][k][4]))
                         
                    c = c + 1    
                    b = box[0:4]
                    (centerX, centerY, width, height) = b.astype("int")
                    print(centerX,centerY,width,height)
                    
                    
                    
                    bxs.append([int(centerX),int(centerY),int(width),int(height)])
                    
                    cids.append(j)
                    
            
                    cv2.rectangle(img,(box[0],box[1]),(box[2],box[3]),(0,255,0),1)
                   
                    cv2.putText(img, lab, (box[0],box[1]), cv2.FONT_HERSHEY_SIMPLEX, .5, (255,0,0), lineType=cv2.LINE_AA)
        cnt.append(c)
        if len(cnt)==5:
          txt = classes[str(1)]+" "+ str(cnt[0]) +"  " +classes[str(2)]+" "+ str(cnt[1]) +"  "+classes[str(3)]+" "+ str(cnt[2]) + "  "+classes[str(5)]+" "+ str(cnt[3]) + "  "+classes[str(7)]+" "+ str(cnt[4])
          cv2.putText(img,"{}".format(txt),(10,30),cv2.FONT_HERSHEY_SIMPLEX, .5, (0, 0, 255))
        print(lab,": ",c)
               
cv2_imshow(img)

ids = cv2.dnn.NMSBoxes(bxs, confidence, 0.40, 0.01) 
print(ids)

f = ids.flatten()
print(f)

from keras import backend as K

K.set_learning_phase(0)

from keras.models import load_model

model = load_model("q2w.h5")

print(model.inputs)
print(model.outputs)

def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):
    from tensorflow.python.framework.graph_util import convert_variables_to_constants
    graph = session.graph
    with graph.as_default():
        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))
        output_names = output_names or []
        output_names += [v.op.name for v in tf.global_variables()]
        # Graph -> GraphDef ProtoBuf
        input_graph_def = graph.as_graph_def()
        if clear_devices:
            for node in input_graph_def.node:
                node.device = ""
        frozen_graph = convert_variables_to_constants(session, input_graph_def,
                                                      output_names, freeze_var_names)
        return frozen_graph


frozen_graph = freeze_session(K.get_session(),
                              output_names=[out.op.name for out in model.outputs])

tf.train.write_graph(frozen_graph, "model", "tf_model.pb", as_text=False)

from tensorflow.python.platform import gfile

f = gfile.FastGFile("./model/tf_model.pb", "rb")

graph_def  = tf.GraphDef()

graph_def.ParseFromString(f.read())

f.close()

sess = tf.Session()
sess.graph.as_default()

tf.import_graph_def(graph_def)

softmax_tensor = sess.graph.get_tensor_by_name('import/dense_4/Softmax:0')
print(softmax_tensor)

label_file = "car_names.txt"
label = []
with open(label_file, "r", encoding='cp1251') as ins:
    for line in ins:
        label.append(line.rstrip())

print(label)

label_fil = "coco.txt"
labelzz = []
with open(label_fil, "r", encoding='cp1251') as ins:
    for line in ins:
        labelzz.append(line.rstrip())

print(labelzz)

from PIL import Image, ImageOps

im = cv2.imread("b.jpg")
im = cv2.resize(im,(416,416))
if len(ids)>0:
  for i in ids.flatten():
    (x,y) = (bxs[i][0],bxs[i][1])
    
    (w,h) = (bxs[i][2],bxs[i][3])
    


    color = [int(cr) for cr in COLORS[cids[i]]]
    if cids[i] == 2 or cids[i]==7:
      
      img1[max(y,0):y+h,max(x,0):x+w]
      imgs = img1[:,:,::-1] 
      size = (224,224)      
      padColor=0
      h1, w1 = imgs.shape[:2]
      sh, sw = size
      if h1 > sh or w1 > sw:
        interp = cv2.INTER_AREA
      else: 
        interp = cv2.INTER_CUBIC

          
      aspect = w1/h1  

          
      if aspect > 1:
        new_w = sw
        new_h = np.round(new_w/aspect).astype(int)
        pad_vert = (sh-new_h)/2
        pad_top, pad_bot = np.floor(pad_vert).astype(int), np.ceil(pad_vert).astype(int)
        pad_left, pad_right = 0, 0
      elif aspect < 1: 
        new_h = sh
        new_w = np.round(new_h*aspect).astype(int)
        pad_horz = (sw-new_w)/2
        pad_left, pad_right = np.floor(pad_horz).astype(int), np.ceil(pad_horz).astype(int)
        pad_top, pad_bot = 0, 0
      
      else: 
        new_h, new_w = sh, sw
        pad_left, pad_right, pad_top, pad_bot = 0, 0, 0, 0

          
      if len(imgs.shape) is 3 and not isinstance(padColor, (list, tuple, np.ndarray)): 
        padColor = [padColor]*3

          
      scaled_img = cv2.resize(imgs, (new_w, new_h), interpolation=interp)
      scaled_img = cv2.copyMakeBorder(scaled_img, pad_top, pad_bot, pad_left, pad_right, borderType=cv2.BORDER_CONSTANT, value=padColor)



      imgs = scaled_img
      imgs = np.expand_dims(imgs,axis=0)
      imgs = imgs.astype(np.float32)
      imgs /= 127.5
      imgs -=1.

      
      predictions = sess.run(softmax_tensor, {'import/vgg16_input:0': imgs})

      predictions = np.squeeze(predictions)

      top = 3
      top_indices = predictions.argsort()[-top:][::-1]
      
      cls = []
      make_model = []
      for m in top_indices:
        make_model = label[m].strip('')
        
        cls.append({"CarName": make_model,"prob":str(predictions[m])})
      
      

      text = "{}:{:.4f}".format(cls[0]['CarName'], float(cls[0]['prob']))
      cv2.putText(im, text, (x+2,y+20), cv2.FONT_HERSHEY_SIMPLEX,0.6, (0,255,0),1)
      
    

    cv2.rectangle(im, (x,y),(w,h),color,2)
    text = "{}: {:.4f}".format(labelzz[cids[i]], confidence[i])
    cv2.putText(im,"{}".format(txt),(20,50),cv2.FONT_HERSHEY_SIMPLEX, .5, (0,0,255))
    cv2.putText(im,text,(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,1)


cv2_imshow(im)

